# -*- coding: utf-8 -*-
"""K-pop_Model_Building.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11wtoR6I51Nky2fiLa46KyJYjm4wb1Mbk

#**Analyzing K-Pop Using Machine Learning**
#Part 3:â€ŠModel Building

- Author: Jaemin Lee (aka. Import Data)

- [Import Data YouTube Channel](https://www.youtube.com/channel/UCYDacpfRrCX6_8oDDlzTgFw)

- [Dataset Link](https://github.com/importdata/kpop-analysis/blob/master/fully%20cleaned%20kpop%20data.csv)
- [Medium Blog](https://towardsdatascience.com/analyzing-k-pop-using-machine-learning-part-3-model-building-c19149964a22?source=friends_link&sk=bdc6d70ddd2b57bec5b29e3990bbb833)

# Import Basic Libraries
"""

import pandas as pd
import numpy as np

"""# Import Data"""

df = pd.read_csv("C:/Users/jaemi/Desktop/Tutorial Datasets/kpop/fully cleaned kpop data.csv")


# subset relevant columns for model

df_model = df[['popl_by_co_yn', 'reason', 'yr_listened', 'gender_pref',
       'daily_music_hr', 'watch_MV_yn', 'daily_MV_hr', 'obsessed_yn',
       'news_medium', 'pursuit', 'time_cons_yn', 'life_chg', 'pos_eff',
       'yr_merch_spent', 'money_src', 'concert_yn', 'crazy_ev', 'age',
       'country', 'job', 'gender', 'num_gr_like', 'bts_vs_others']]


# get dummy data to convert categorical variable into dummy/indicator variables
df_dum = pd.get_dummies(df_model)
df_dum

df_real = df[["yr_listened", "daily_music_hr", "daily_MV_hr", "yr_merch_spent", "age", "num_gr_like"]]


"""# Train and Test Split (80/20)"""

from sklearn.model_selection import train_test_split

X = df_real.drop('daily_music_hr', axis = 1)
X
y = df_real.daily_music_hr 
y.value_counts()

# 80/20 train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)



"""# [XGBoost](https://xgboost.readthedocs.io/en/latest/)"""

#from xgboost import XGBClassifier


import xgboost as xgb

# initialize the linear regression model
xgb_clf = xgb.sklearn.XGBClassifier(nthread = -1, seed = 1)

# train the model
xgb_clf.fit(X_train, y_train)


# Tune XGBoost using GridSearchCV

from sklearn.model_selection import GridSearchCV


params = {'min_child_weight': [5], 'gamma': [1], 'subsample': [0.8, 1.0],
          'colsample_bytree': [0.6, 0.8], 'max_depth': [1,2]}

gs_xgb = GridSearchCV(xgb_clf, params ,scoring = 'neg_mean_absolute_error', cv = 10)

gs_xgb.fit(X_train, y_train)

gs_xgb.best_score_

xgb_best = gs_xgb.best_estimator_
xgb_best

xgb_best.fit(X_train, y_train)


#############################################################################################
# linear regression
'''
from sklearn.linear_model import LinearRegression
lm = LinearRegression()

lm.fit(X_train, y_train)
'''

import pickle

# save the model to disk
with open('model.pkl', 'wb') as file:
    pickle.dump(xgb_best, file)


#pickle.dump(xgb_best, open('model.pkl','wb'))
#pickle.dump(lm, open('model.pkl','wb'))

# load the model to compare the results
#model = pickle.load(open('model.pkl','rb'))




